---
kep-number: 29
title: Node Fencing KEP
authors:
  - "@beekhof"
owning-sig: sig-node
participating-sigs:
  - sig-cluster-lifecycle
  - sig-storage
reviewers:
  - TBD
  - "@thockin"
  - "@smarterclayton"
approvers:
  - TBD
editor: TBD
creation-date: 2018-09-19
last-updated: 2018-09-19
status: provisional
see-also:
replaces:
superseded-by:
---

# Node Fencing

## Table of Contents

* [Table of Contents](#table-of-contents)
* [Summary](#summary)
* [Motivation](#motivation)
    * [Goals](#goals)
    * [Non-Goals](#non-goals)
* [Proposal](#proposal)
    * [Implementation Details/Notes/Constraints [optional]](#implementation-detailsnotesconstraints-optional)
    * [Risks and Mitigations](#risks-and-mitigations)
* [Graduation Criteria](#graduation-criteria)
* [Implementation History](#implementation-history)
* [Drawbacks [optional]](#drawbacks-optional)
* [Alternatives [optional]](#alternatives-optional)

## Summary

The loss of a worker node should be transparent to users of StatefulSets and
RWO Volumes. Recovery time for affected Pods and Volumes should be bounded and
short, allowing workloads to be recovered elsewhere and scale up/down events
to proceed.

## Motivation

Neither software, the hardware it runs on, nor the networks that connect them
are perfect.  

Attempts to automatically preserve availabilty in the presence of errors is
hampered by failures of peer hardware being generally indistinguishable from
the failure of network and/or software stack.

Using other communication paths can allow the system to know that the peer is
alive in some capacity, but unless the peer can take steps to recover itself
in a timely manner, this information is of little use.

Unlike ReplicaSets which can assume the best and spin up new instances, this
has problematic consequences for anything seeking to provide at-most-one
semantics.  Especially Stateful Sets which cannot scale up or down while one
of its members is in a failed state.

Fencing is a well established concept that allows a system to know for sure
that it is safe to recover these kinds of workloads to other peers.
Fundamentally it answers the question: _Is this peer capabale of corrupting my
data?_ With a resounding _No_, and based on that the system can then safely
initiate recovery.

The traditional non-cloud mechansim for this is to power off the physical
hardware.  More optimistic implementions power cycle the hardware in the hope
that it will return to a functional state.  Other more complex systems will
seek to isolate the peer from the network (so that no additional requests can
be consumed) and the disk (preventing the double writers problem) in order to
allow triage activities to take place.

### Experience reports

* Cheng Xing [AttachDetachController fails to force detach on pod deletion](https://github.com/kubernetes/kubernetes/issues/65392) June 2018
* Clayton Colman [Pod Safety](https://github.com/kubernetes/community/blob/16f88595883a7461010b6708fb0e0bf1b046cf33/contributors/design-proposals/pod-safety.md) October 2016


### Goals

* Specify where implementations should look in order to determine if a node requires fencing
* Specify how implementations should indicate a node needs to be fenced
* Specify how implementations should indicate a node has been sucessfully fenced
* Specify how nodes should return to a "normal" state
* Specify the changes required to Kubernetes that enable automated recovery in the presense of worker failures
* Provide a sample implementation based on the [Machine](https://github.com/kubernetes-sigs/cluster-api/blob/master/docs/proposals/machine-api-proposal.md) API 

### Non-Goals

It is explicitly _not_ the goal of this work to:

* Have fencing become a requirement for all Kubernetes deployments
* Have the community converge on a particular fencing implementation

## Proposal

Setting and unsetting the NodeConditions form the primary contract between
implementations and the rest of the system.

The contract consists of three additional NodeConditions:

* a `FencingTriaged` NodeCondition.  `True` if the node has been identified as
being in a non-ideal state.  Otherwise `False`.

* a `FencingRequired` NodeCondition.  `True` if the the node needs to be
fenced, otherwise `False`. This is a distinct condition from `FencingTriaged`
as policy may dictate that it should not be fenced (at least not yet).

* a `FencingComplete` NodeCondition. `True` if the node has been fenced, otherwise `False`.

We also propose two additional non-mandatory taints:

* a `node.kubernetes.io/fencingrequired` `NoSchedule` taint corresponding to
NodeCondition `FencingRequired` being  `True`

* a `node.kubernetes.io/fencingtriaged` `PreferNoSchedule` taint
corresponding to NodeCondition `FencingRequired` being  `True`

Finally we propose a Fencing Request CRD, which borrows from the Job syntax,
for allowing admins to trigger fencing manually.

```go

type FencingRequest struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	Spec   FencingRequestSpec   `json:"spec,omitempty"`
	Status FencingRequestStatus `json:"status,omitempty"`
}

type FencingRequestSpec struct {
	// This ObjectMeta will autopopulate the Node created. Use this to
	// indicate what labels, annotations, name prefix, etc., should be used
	// when creating the Node.
	// +optional
	metav1.ObjectMeta `json:"metadata,omitempty"`

	// A pointer to the Node object requiring fencing
	NodeRef *corev1.ObjectReference `json:"nodeRef,omitempty"`
}

// FencingRequestStatus defines the observed state of FencingRequest
type FencingRequestStatus struct {
	// The latest available observations of an object's current state.
	// +optional
	// +patchMergeKey=type
	// +patchStrategy=merge
	Conditions []JobCondition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"`

	// Represents time when the request was acknowledged by the controller.
	// It is represented in RFC3339 form and is in UTC.
	// +optional
	StartTime *metav1.Time `json:"startTime,omitempty" protobuf:"bytes,2,opt,name=startTime"`

	// Represents time when the request was completed.
	// It is represented in RFC3339 form and is in UTC.
	// +optional
	CompletionTime *metav1.Time `json:"completionTime,omitempty" protobuf:"bytes,3,opt,name=completionTime"`

	// In the event that there is a terminal problem fencing the node
	// both ErrorReason and ErrorMessage will be set. ErrorReason
	// will be populated with a succinct value suitable for FencingRequest
	// interpretation, while ErrorMessage will contain a more verbose
	// string suitable for logging and human consumption.
	// +optional
	ErrorReason *clustercommon.FencingRequestStatusError `json:"errorReason,omitempty"`
	// +optional
	ErrorMessage *string `json:"errorMessage,omitempty"`

	// Provider-specific status.
	// It is recommended that providers maintain their
	// own versioned API types that should be
	// serialized/deserialized from this field.
	ProviderStatus *runtime.RawExtension `json:"providerStatus"`
}

```


### Timeline of a Failure:

1. A healthy node is represented by the tuple

    > FencingTriaged = False, FencingRequired = False, FencingComplete = False

1. Immediately after (for example) seeing the `Ready` condition change to
    `Unknown` , the fencing implementation will notice this and update the fencing
    conditions to:

    > FencingTriaged = True, FencingRequired = False, FencingComplete = False

    *Only* NodeConditions should be used by implementations in order to
    determine if a node requires fencing.

    If additional information is required, it should be made available by
    augmenting the existing the list of NodeConditions using something like
    [Node Problem Detector](https://github.com/kubernetes/node-problem-detector/)

    Including error condition detection in fencing implementations should be
    avoided.

1. Depending on the implementation's configuration, it may then update the
    fencing conditions to:

    > FencingTriaged = True, FencingRequired = True, FencingComplete = False

	Inputs to this decision may include:

	* How long the `Ready` condition remains `Unknown`,
	* The state of other Node Conditions,
	* If the node is a Kubernetes master,
	* What workloads exist on the machine,
	* Other useful information

1. Next, implementations create a FencingRequest in which to record the
    recovery progress, completion, and final result.

1. Once the implementation determines that the node is now in a safe state, it
	will update the fencing conditions to:

	> FencingTriaged = True, FencingRequired = True, FencingComplete = True

	Fencing implementations must only set `FencingComplete=True` once it has
	confirmed any workloads on the node have been isolated from the network and
	any shared resources.  Most commonly this will mean the node has been
	powered off.

1. Relevant controllers, watching for this state, can now take the appropriate
actions to allow recovery of the affected node's workload by force deleting
Pods and Volumes.

1. Controllers may also wish to use other values as triggers to change
behaviour or perform relevant functionality.

1. Implementations return Nodes to a "normal" state by removing the
   `FencingTriaged`, `FencingComplete` and `FencingRequired` NodeConditions.

   This could occur periodically or more likely, when the NodeConditions that
   were determined to require fencing are no longer present.

### Implementation Details/Notes/Constraints

#### Node Conditions

As setting and unsetting the `NodeConditions` form the primary contract between
implementations and the rest of the system, implementations should consider
failure modes that include or co-incide with interruptions to the service
network between nodes and `apiservers`.

For additional inputs to the repair logic, we rely on NPD which runs locally
on each node. In the presence of a service network failure, NPD would not be
able to set additional `NodeConditions`. However the fact that the node is
disconnected should already be sufficient to trigger fencing of the affected
nodes.

Since the fencing implementation is responsible for setting and clearing
`FencingTriaged`, `FencingRequired`, `FencingComplete`,  any disruption to the
service network between it and the `apiservers` is also important to consider.

In our implementation there are multiple copies that vote for a leader, the
presence of a service network failure affecting the elected controller results
in it being unable to renew its lease and one of its peers (on another node
that by definitiion still has connectivity) taking over and being able to set
`NodeConditions`.

In the presence of a total failure, then we shouldn't be fencing anyway so
there would be no need to set any `NodeConditions`.

#### Power Management

Since the most common form of fencing involves powering off nodes, co-
ordination with other entities that may be involved with power management
should be considered...

TBC

### Risks and Mitigations

TBA

## Graduation Criteria

TBA

## Implementation History

- Initial version: 2018-09-19
- Incorporate review feedback: 2018-11-01
  - Avoid the use of `should`
  - Explain the design by using a failed node as an example
  - Avoid overloading `NodeFencingRequired` for admin requests
  - Indicate the flavour of new taints and make them optional

## Drawbacks

TBA

## Alternatives

Instead of requiring every controller to look for `FencingRequired` = `True`
**and** `FencingComplete` = `True`, one entity (possibly the node lifecycle
controller, or the fencing implementation) could take that responsibility.

Another option is for this entity to delete the affected Nodes (instead of
directly deleting Pods and Volumes) from Kubernetes. This might be sufficient
for existing controllers such as AttachDetachController to trigger cleanup
logic.

However in deleting the Node object, we are also removing the history of
events that triggered fencing. Although this would be recorded in logs and
optionally by the fencing logic.



## Infrastructure Needed [optional]

* A repository for the logic that triggers fencing
* A branch in which changes to Kubernetes controllers such as the Node Lifecycle Controller and Attach Detach Controller can be evaluated
